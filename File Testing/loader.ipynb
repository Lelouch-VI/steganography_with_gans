{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOmRzmMyv3wi0bGqIy0h5CF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xazsdE7ni6v3","executionInfo":{"status":"ok","timestamp":1724455328924,"user_tz":360,"elapsed":4702,"user":{"displayName":"a c","userId":"04528162853162008379"}},"outputId":"6e1abe0e-27c8-43aa-d82d-0a287ec7032c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting reedsolo\n","  Downloading reedsolo-1.7.0-py3-none-any.whl.metadata (23 kB)\n","Downloading reedsolo-1.7.0-py3-none-any.whl (32 kB)\n","Installing collected packages: reedsolo\n","Successfully installed reedsolo-1.7.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1fM_UrdUYTQ8"},"outputs":[],"source":["''' LIBRARIES '''\n","import os\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import datasets, transforms\n","\n","from PIL import Image"]},{"cell_type":"code","source":["''' LOADING DATA\n","References (see these to understand the basis):\n","  Data Loader from the original SteganoGAN GitHub: https://github.com/DAI-Lab/SteganoGAN/blob/master/steganogan/loader.py\n","  IStego100k Dataset: https://arxiv.org/abs/1911.05542\n","\n","So this has three components:\n","  Preprocessing (transformations):\n","    By design, all of the images in IStego100k dataset are constrained to being (a) 1024*1024 and (b) diverse in composition\n","    However, data processing is one of the more challenging prospects of ML, and it can lead to much worse outcomes over time\n","    As such, is crucial to have adequate methods of preprocessing data\n","    These are:\n","      Normalization - Altering the pixel values so that they fall between a standardized range of values (typically [-1,1]), which center the pixel values around zero\n","        In its normalization parameters, SteganoGAN normalizes to [.5,.5,.5]\n","      Random Horizontal Flip - Flips the image to diversify the dataset at random to increase diversity and avoid overfitting\n","      Data Augmentation and Alteration - Increasing diversity lowering chances of overfitting by altering the features of the image (for instance, changing its resolution)\n","      Tensor Conversion - Converts the data to a pytorch tensor, which is the data structure necessary for training a pytorch-based model\n","\n","  Dataset:\n","    In place of a normal Dataset class, SteganoGAN utilizes a custom ImageFolder class inherited from torchvision.datasets: https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html\n","    This helps with processing image data where the images are already organized according to some kind of directory structure (e.g. the MSCOCO dataset)\n","    Expecting this structure as input, the loader can then create custom classes, where each subfolder is processed as a separate class.\n","      (since ImageFolder inherits from DatasetFolder, another pytorch class, you can also use this to create custom datasets)\n","    Including this allows you to limit the number of images processed to those of certain classes.\n","\n","    My dataset is relatively small and thus does not need to be reduced in size or organized by directory. As a result, I did not implement an ImageFolder class.\n","    Instead I opted to do a more standard image processing Dataset class.\n","\n","  DataLoader:\n","    SteganoGAN implements a custom DataLoader, also inherited from torch.utils.data.DataLoader: https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n","\n","    While this may be true of the original, I am striving to introduce some degree of novelty in my own implementation.\n","    Therefore, as it adequately fits my needs, I will be implementing my own custom DataLoader.\n","    However, I will be taking significant inspiration from SteganoGAN on this front, essentially ending at the same ends by different means\n","'''\n","\n","default_transform = transforms.Compose([\n","    transforms.Resize((256, 256)),  # resize, adjust as needed\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),  # Convert PIL image to tensor\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to SteganoGAN standard\n","])\n","\n","\n","# DATA SET\n","class MyDataset(Dataset):\n","  def __init__(self, cover_imgs, stego_imgs, transform=None, num_classes=2):\n","    if len(cover_imgs) != len(stego_imgs): # the lists should be the same length\n","      raise ValueError(\"Cover images and stego images lists must be of the same length.\")\n","\n","    self.cover_imgs = cover_imgs\n","    self.stego_imgs = stego_imgs\n","    self.transform = transform if transform else default_transform\n","\n","  def __len__(self): # length\n","    return len(self.cover_imgs)\n","\n","  def __getitem__(self, index): # fetch an item, return the tensor\n","    try:\n","      cover_img = Image.open(self.cover_imgs[index]).convert(\"RGB\")\n","      stego_img = Image.open(self.stego_imgs[index]).convert(\"RGB\")\n","    except Exception as e: # exception\n","      raise RuntimeError(f\"Error loading image at index {index}: {e}\")\n","\n","\n","    if self.transform:\n","      cover_img = self.transform(cover_img)\n","      stego_img = self.transform(stego_img)\n","\n","    return cover_img, stego_img\n","\n","\n","# DATA LOADER\n","def create_data_loader(cover_imgs, stego_imgs, transform, shuffle=False, num_workers=4, batch_size=4):\n","  dataset = MyDataset(cover_imgs, stego_imgs, transform)\n","  return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)"],"metadata":{"id":"9xiQt4llYeto"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["''' TEST '''\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","\n","\n","# Example paths (replace these with your actual image paths)\n","base_dir = '/content/drive/My Drive/DU/COMP 3432 Machine Learning/Imgs'\n","\n","cover_dir = os.path.join(base_dir, 'Cover')\n","stego_dir = os.path.join(base_dir, 'Stego')\n","\n","# List all image files in the cover directory\n","cover_imgs = sorted([os.path.join(cover_dir, f) for f in os.listdir(cover_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n","\n","# List all image files in the stego directory\n","stego_imgs = sorted([os.path.join(stego_dir, f) for f in os.listdir(stego_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n","\n","# Create the data loader with shuffle=True\n","data_loader = create_data_loader(cover_imgs, stego_imgs, transform=None, batch_size=4, shuffle=True, num_workers=0)\n","\n","# Iterate over the data loader and verify\n","for batch_idx, (cover_batch, stego_batch) in enumerate(data_loader):\n","    print(f\"Batch {batch_idx + 1}\")\n","    fig, axs = plt.subplots(2, len(cover_batch), figsize=(15, 6))\n","\n","    for i in range(len(cover_batch)):\n","        # Convert tensor to numpy for visualization\n","        cover_img_np = cover_batch[i].permute(1, 2, 0).numpy()\n","        stego_img_np = stego_batch[i].permute(1, 2, 0).numpy()\n","\n","        # De-normalize if necessary for visualization\n","        cover_img_np = (cover_img_np * 0.5) + 0.5\n","        stego_img_np = (stego_img_np * 0.5) + 0.5\n","\n","        # Plot cover image\n","        axs[0, i].imshow(cover_img_np)\n","        axs[0, i].set_title(f'Cover Image {i+1}')\n","        axs[0, i].axis('off')\n","\n","        # Plot stego image\n","        axs[1, i].imshow(stego_img_np)\n","        axs[1, i].set_title(f'Stego Image {i+1}')\n","        axs[1, i].axis('off')\n","\n","    plt.show()\n","\n","    # Stop after one batch for demonstration purposes\n","    if batch_idx == 0:\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":386},"id":"TQBrbei61JQv","executionInfo":{"status":"error","timestamp":1724451646289,"user_tz":360,"elapsed":6811,"user":{"displayName":"a c","userId":"04528162853162008379"}},"outputId":"e17da6bf-d958-47cd-b690-e1a0b0ea83f1"},"execution_count":1,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-487e8f75b001>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]}]}