{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNG1GVQOs8gTxa98TiGjp/1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bcVOD8b7xOi8"},"outputs":[],"source":["''' LIBRARIES '''\n","import torch\n","from torch import nn\n","import torch.nn.functional as F"]},{"cell_type":"code","source":["class Mish(nn.Module):\n","  def forward(self, x):\n","    return x * torch.tanh(F.softplus(x))"],"metadata":{"id":"weN520uJU-7x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Encoder from SteganoGAN, this time re-implemented with Mish() instead of LeakyReLU\n","\n","class BasicMishEncoder(nn.Module):\n","  \"\"\"\n","  The BasicEncoder module takes an cover image and a data tensor and combines\n","  them into a steganographic image.\n","\n","  Input: (N, 3, H, W), (N, D, H, W)\n","  Output: (N, 3, H, W)\n","  \"\"\"\n","\n","  add_image = False\n","\n","  def _conv2d(self, in_channels, out_channels):\n","    return nn.Conv2d(\n","      in_channels=in_channels,\n","      out_channels=out_channels,\n","      kernel_size=3,\n","      padding=1\n","    )\n","\n","  def _build_models(self):\n","    self.features = nn.Sequential(\n","      self._conv2d(3, self.hidden_size),\n","      Mish(),\n","      nn.BatchNorm2d(self.hidden_size),\n","    )\n","    self.layers = nn.Sequential(\n","      self._conv2d(self.hidden_size + self.data_depth, self.hidden_size),\n","      Mish(),\n","      nn.BatchNorm2d(self.hidden_size),\n","      self._conv2d(self.hidden_size, self.hidden_size),\n","      Mish(),\n","      nn.BatchNorm2d(self.hidden_size),\n","      self._conv2d(self.hidden_size, 3),\n","      nn.Tanh(),\n","    )\n","    return self.features, self.layers\n","\n","  def __init__(self, data_depth, hidden_size):\n","    super().__init__()\n","    self.data_depth = data_depth\n","    self.hidden_size = hidden_size\n","    self._models = self._build_models()\n","\n","\n","  def forward(self, image, data):\n","    x = self._models[0](image)\n","    x_list = [x]\n","\n","    for layer in self._models[1:]:\n","      x = layer(torch.cat(x_list + [data], dim=1))\n","      x_list.append(x)\n","\n","    if self.add_image:\n","      x = image + x\n","\n","    return x\n","\n","\n","\n","class ResidualMishEncoder(BasicEncoder):\n","  \"\"\"\n","  The ResidualEncoder module takes an cover image and a data tensor and combines\n","  them into a steganographic image.\n","\n","  Input: (N, 3, H, W), (N, D, H, W)\n","  Output: (N, 3, H, W)\n","  \"\"\"\n","\n","  add_image = True\n","\n","  def _build_models(self):\n","    self.features = nn.Sequential(\n","      self._conv2d(3, self.hidden_size),\n","      Mish(),\n","      nn.BatchNorm2d(self.hidden_size),\n","    )\n","    self.layers = nn.Sequential(\n","      self._conv2d(self.hidden_size + self.data_depth, self.hidden_size),\n","      Mish(),\n","      nn.BatchNorm2d(self.hidden_size),\n","      self._conv2d(self.hidden_size, self.hidden_size),\n","      Mish(),\n","      nn.BatchNorm2d(self.hidden_size),\n","      self._conv2d(self.hidden_size, 3),\n","    )\n","    return self.features, self.layers\n","\n","\n","class DenseMishEncoder(BasicEncoder):\n","  \"\"\"\n","  The DenseEncoder module takes an cover image and a data tensor and combines\n","  them into a steganographic image.\n","\n","  Input: (N, 3, H, W), (N, D, H, W)\n","  Output: (N, 3, H, W)\n","  \"\"\"\n","\n","  add_image = True\n","\n","  def _build_models(self):\n","    self.conv1 = nn.Sequential(\n","      self._conv2d(3, self.hidden_size),\n","      Mish(),\n","      nn.BatchNorm2d(self.hidden_size),\n","    )\n","    self.conv2 = nn.Sequential(\n","      self._conv2d(self.hidden_size + self.data_depth, self.hidden_size),\n","      Mish(),\n","      nn.BatchNorm2d(self.hidden_size),\n","    )\n","    self.conv3 = nn.Sequential(\n","      self._conv2d(self.hidden_size * 2 + self.data_depth, self.hidden_size),\n","      Mish(),\n","      nn.BatchNorm2d(self.hidden_size),\n","    )\n","    self.conv4 = nn.Sequential(\n","      self._conv2d(self.hidden_size * 3 + self.data_depth, 3)\n","    )\n","\n","    return self.conv1, self.conv2, self.conv3, self.conv4"],"metadata":{"id":"I1OQKNDQPQ9n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Encoder from SteganoGAN, this time re-implemented with Mish() instead of LeakyReLU\n","\n","class BasicMishDecoder(nn.Module):\n","  \"\"\"\n","  The BasicDecoder module takes an steganographic image and attempts to decode\n","  the embedded data tensor.\n","\n","  Input: (N, 3, H, W)\n","  Output: (N, D, H, W)\n","  \"\"\"\n","\n","  def _conv2d(self, in_channels, out_channels):\n","    return nn.Conv2d(\n","      in_channels=in_channels,\n","      out_channels=out_channels,\n","      kernel_size=3,\n","      padding=1\n","    )\n","\n","  def _build_models(self):\n","    self.layers = nn.Sequential(\n","      self._conv2d(3, self.hidden_size),\n","      Mish(),\n","      nn.BatchNorm2d(self.hidden_size),\n","\n","      self._conv2d(self.hidden_size, self.hidden_size),\n","      Mish(),\n","      nn.BatchNorm2d(self.hidden_size),\n","\n","      self._conv2d(self.hidden_size, self.hidden_size),\n","      Mish(),\n","      nn.BatchNorm2d(self.hidden_size),\n","\n","      self._conv2d(self.hidden_size, self.data_depth)\n","    )\n","\n","    return [self.layers]\n","\n","  def __init__(self, data_depth, hidden_size):\n","    super().__init__()\n","    self.data_depth = data_depth\n","    self.hidden_size = hidden_size\n","\n","    self._models = self._build_models()\n","\n","  def forward(self, x):\n","    x = self._models[0](x)\n","\n","    if len(self._models) > 1:\n","      x_list = [x]\n","      for layer in self._models[1:]:\n","        x = layer(torch.cat(x_list, dim=1))\n","        x_list.append(x)\n","\n","    return x\n","\n","\n","class DenseMishDecoder(BasicDecoder):\n","    \"\"\"\n","    The DenseDecoder module takes an steganographic image and attempts to decode\n","    the embedded data tensor.\n","\n","    Input: (N, 3, H, W)\n","    Output: (N, D, H, W)\n","    \"\"\"\n","    def _build_models(self):\n","      self.conv1 = nn.Sequential(\n","        self._conv2d(3, self.hidden_size),\n","        Mish(),\n","        nn.BatchNorm2d(self.hidden_size)\n","      )\n","\n","      self.conv2 = nn.Sequential(\n","        self._conv2d(self.hidden_size, self.hidden_size),\n","        Mish(),\n","        nn.BatchNorm2d(self.hidden_size)\n","      )\n","\n","      self.conv3 = nn.Sequential(\n","        self._conv2d(self.hidden_size * 2, self.hidden_size),\n","        Mish(),\n","        nn.BatchNorm2d(self.hidden_size)\n","      )\n","\n","      self.conv4 = nn.Sequential(self._conv2d(self.hidden_size * 3, self.data_depth))\n","\n","      return self.conv1, self.conv2, self.conv3, self.conv4"],"metadata":{"id":"2oFV94djiNP_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["''' TEST '''\n","\n","import torch\n","from PIL import Image\n","from torchvision import transforms\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Set the parameters for testing\n","hidden_size = 64\n","data_depth = 3\n","\n","# Define the transform to preprocess the image (resize, normalize, and convert to tensor)\n","transform = transforms.Compose([\n","  transforms.Resize((224, 224)),\n","  transforms.ToTensor(),\n","  transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","])\n","\n","# Load a cover image from Google Drive\n","cover_image_path = '/content/drive/My Drive/DU/COMP 3432 Machine Learning/Imgs/Cover/100000.jpg'\n","cover_image = Image.open(cover_image_path).convert('RGB')\n","cover_image_tensor = transform(cover_image).unsqueeze(0)  # Add batch dimension\n","\n","# Create dummy data tensor\n","dummy_data_tensor = torch.randn(1, data_depth, 224, 224)\n","\n","print(\"Cover Image Tensor shape:\", cover_image_tensor.shape)\n","print(\"Data Tensor shape:\", dummy_data_tensor.shape)\n","\n","\n","def test_basic_encoder_decoder_with_images(cover_image_tensor, dummy_data_tensor):\n","  basic_encoder = BasicEncoder(data_depth=data_depth, hidden_size=hidden_size)\n","  basic_decoder = BasicDecoder(data_depth=data_depth, hidden_size=hidden_size)\n","\n","  # Encode the data into the cover image\n","  stego_image = basic_encoder(cover_image_tensor, dummy_data_tensor)\n","  print(\"Stego Image shape:\", stego_image.shape)\n","\n","  # Decode the stego image to retrieve the data\n","  retrieved_data = basic_decoder(stego_image)\n","  print(\"Retrieved Data shape:\", retrieved_data.shape)\n","\n","  assert retrieved_data.shape == dummy_data_tensor.shape, \"Basic Encoder-Decoder test failed!\"\n","  print(\"Basic Encoder-Decoder test passed.\")\n","\n","def test_dense_encoder_decoder_with_images(cover_image_tensor, dummy_data_tensor):\n","  dense_encoder = DenseEncoder(data_depth=data_depth, hidden_size=hidden_size)\n","  dense_decoder = DenseDecoder(data_depth=data_depth, hidden_size=hidden_size)\n","\n","  # Encode the data into the cover image\n","  dense_stego_image = dense_encoder(cover_image_tensor, dummy_data_tensor)\n","  print(\"Dense Stego Image shape:\", dense_stego_image.shape)\n","\n","  # Decode the stego image to retrieve the data\n","  dense_retrieved_data = dense_decoder(dense_stego_image)\n","  print(\"Dense Retrieved Data shape:\", dense_retrieved_data.shape)\n","\n","  assert dense_retrieved_data.shape == dummy_data_tensor.shape, \"Dense Encoder-Decoder test failed!\"\n","  print(\"Dense Encoder-Decoder test passed.\")\n","\n","# Run the tests with real images\n","test_basic_encoder_decoder_with_images(cover_image_tensor, dummy_data_tensor)\n","test_dense_encoder_decoder_with_images(cover_image_tensor, dummy_data_tensor)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J8ajmd54nlBw","executionInfo":{"status":"ok","timestamp":1724424359365,"user_tz":360,"elapsed":5723,"user":{"displayName":"a c","userId":"04528162853162008379"}},"outputId":"848ead58-6f53-4bad-f189-145f9243f6f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Cover Image Tensor shape: torch.Size([1, 3, 224, 224])\n","Data Tensor shape: torch.Size([1, 3, 224, 224])\n","Stego Image shape: torch.Size([1, 3, 224, 224])\n","Retrieved Data shape: torch.Size([1, 3, 224, 224])\n","Basic Encoder-Decoder test passed.\n","Dense Stego Image shape: torch.Size([1, 3, 224, 224])\n","Dense Retrieved Data shape: torch.Size([1, 3, 224, 224])\n","Dense Encoder-Decoder test passed.\n"]}]}]}