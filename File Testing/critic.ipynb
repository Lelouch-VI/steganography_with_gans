{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMxzytlU3exCAJQ5YQl/EGU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":17,"metadata":{"id":"sVI8z5NxxCFd","executionInfo":{"status":"ok","timestamp":1724372653692,"user_tz":360,"elapsed":186,"user":{"displayName":"a c","userId":"04528162853162008379"}}},"outputs":[],"source":["''' LIBRARIES '''\n","import torch\n","from torch import nn\n","from torchvision.models import densenet, resnet\n","import torch.nn.functional as F"]},{"cell_type":"code","source":["# SteganoGAN Critic\n","'''\n","BasicCritic\n","Implemented as a subclass of nn.Module\n","It takes an image and predicts whether it is a cover image or a steganographic image (N, 1).\n","\n","Provided by SteganoGAN:\n","  Input: (N, 3, H, W)\n","  Output: (N, 1)\n","\n","Input Details\n","  Takes a batch of images as input\n","  Parameters - (batch size, num channels, image height, image width)\n","\n","Output Details\n","  Outputs a tensor of shape (N, 1)\n","\n","\n","class BasicCritic(nn.Module):\n","  \"\"\" Conv 2D\n","  Helper function which takes in a 2D convolutional layer of fixed size 3x3\n","  It then standardizes the size of the kernel throughout the model\n","\n","  Parameters:\n","    in_channels - number of input channels. Since this is using images, it is going to be 3 for R, G, and B values\n","    out_channels - number of output channels desired\n","\n","  Details:\n","    Operation - nn.Conv2d extracts spatial features of the input image\n","    kernel_size - ensures a fixed size of\n","  \"\"\"\n","  def _conv2d(self, in_channels, out_channels):\n","    return nn.Conv2d(\n","      in_channels=in_channels,\n","      out_channels=out_channels,\n","      kernel_size=3\n","    )\n","\n","  \"\"\" Build Models\n","  Constructs the network by stacking it layer-by-layer using conv2d in terms of:\n","    Convolutions\n","    Activations\n","    Batch normalizations\n","  \"\"\"\n","  def _build_models(self):\n","    return nn.Sequential( # all returned as one sequential layer\n","      # 1\n","      self._conv2d(3, self.hidden_size),\n","      nn.LeakyReLU(inplace=True),\n","      nn.BatchNorm2d(self.hidden_size),\n","\n","      # 2\n","      self._conv2d(self.hidden_size, self.hidden_size),\n","      nn.LeakyReLU(inplace=True),\n","      nn.BatchNorm2d(self.hidden_size),\n","\n","      # 3\n","      self._conv2d(self.hidden_size, self.hidden_size),\n","      nn.LeakyReLU(inplace=True),\n","      nn.BatchNorm2d(self.hidden_size),\n","\n","      # 4\n","      self._conv2d(self.hidden_size, 1)\n","    )\n","\n","  def __init__(self, hidden_size):\n","    super().__init__()\n","    self.version = '1'\n","    self.hidden_size = hidden_size\n","    self._models = self._build_models()\n","\n","  def upgrade_legacy(self):\n","    \"\"\"Transform legacy pretrained models to make them usable with new code versions.\"\"\"\n","    # Transform to version 1\n","    if not hasattr(self, 'version'):\n","        self._models = self.layers\n","        self.version = '1'\n","\n","  def forward(self, x):\n","    x = self._models(x)\n","    x = torch.mean(x.view(x.size(0), -1), dim=1)\n","\n","    return x\n","\n","'''"],"metadata":{"id":"w6Td-3d6yCyM","colab":{"base_uri":"https://localhost:8080/","height":197},"executionInfo":{"status":"ok","timestamp":1724372571491,"user_tz":360,"elapsed":7,"user":{"displayName":"a c","userId":"04528162853162008379"}},"outputId":"4e9ff4fb-d886-4533-ab05-d0c6aababa41"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nBasicCritic\\nImplemented as a subclass of nn.Module\\nIt takes an image and predicts whether it is a cover image or a steganographic image (N, 1).\\n\\nProvided by SteganoGAN:\\n  Input: (N, 3, H, W)\\n  Output: (N, 1)\\n\\nInput Details\\n  Takes a batch of images as input\\n  Parameters - (batch size, num channels, image height, image width)\\n\\nOutput Details\\n  Outputs a tensor of shape (N, 1)\\n\\n\\nclass BasicCritic(nn.Module):\\n  \"\"\" Conv 2D\\n  Helper function which takes in a 2D convolutional layer of fixed size 3x3\\n  It then standardizes the size of the kernel throughout the model\\n\\n  Parameters:\\n    in_channels - number of input channels. Since this is using images, it is going to be 3 for R, G, and B values\\n    out_channels - number of output channels desired\\n\\n  Details:\\n    Operation - nn.Conv2d extracts spatial features of the input image\\n    kernel_size - ensures a fixed size of\\n  \"\"\"\\n  def _conv2d(self, in_channels, out_channels):\\n    return nn.Conv2d(\\n      in_channels=in_channels,\\n      out_channels=out_channels,\\n      kernel_size=3\\n    )\\n\\n  \"\"\" Build Models\\n  Constructs the network by stacking it layer-by-layer using conv2d in terms of:\\n    Convolutions\\n    Activations\\n    Batch normalizations\\n  \"\"\"\\n  def _build_models(self):\\n    return nn.Sequential( # all returned as one sequential layer\\n      # 1\\n      self._conv2d(3, self.hidden_size),\\n      nn.LeakyReLU(inplace=True),\\n      nn.BatchNorm2d(self.hidden_size),\\n\\n      # 2\\n      self._conv2d(self.hidden_size, self.hidden_size),\\n      nn.LeakyReLU(inplace=True),\\n      nn.BatchNorm2d(self.hidden_size),\\n\\n      # 3\\n      self._conv2d(self.hidden_size, self.hidden_size),\\n      nn.LeakyReLU(inplace=True),\\n      nn.BatchNorm2d(self.hidden_size),\\n\\n      # 4\\n      self._conv2d(self.hidden_size, 1)\\n    )\\n\\n  def __init__(self, hidden_size):\\n    super().__init__()\\n    self.version = \\'1\\'\\n    self.hidden_size = hidden_size\\n    self._models = self._build_models()\\n\\n  def upgrade_legacy(self):\\n    \"\"\"Transform legacy pretrained models to make them usable with new code versions.\"\"\"\\n    # Transform to version 1\\n    if not hasattr(self, \\'version\\'):\\n        self._models = self.layers\\n        self.version = \\'1\\'\\n\\n  def forward(self, x):\\n    x = self._models(x)\\n    x = torch.mean(x.view(x.size(0), -1), dim=1)\\n\\n    return x\\n\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["class Mish(nn.Module):\n","  def forward(self, x):\n","    return x * torch.tanh(F.softplus(x))"],"metadata":{"id":"-QnvB_OhMDFu","executionInfo":{"status":"ok","timestamp":1724372644297,"user_tz":360,"elapsed":170,"user":{"displayName":"a c","userId":"04528162853162008379"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["''' Mish-based Critics '''\n","\n","# BASIC: all returned as one sequential layer\n","class BasicMishCritic(nn.Module):\n","  def _conv2d(self, in_channels, out_channels): # identical to SteganoGAN\n","      return nn.Conv2d(\n","          in_channels=in_channels,\n","          out_channels=out_channels,\n","          kernel_size=3\n","      )\n","\n","\n","  ''' Build models (modified):\n","  Instead of directly creating the\n","  '''\n","  def _build_models(self):\n","    self.c1 = nn.Sequential( # 1\n","      self._conv2d(3, self.hidden_size),\n","      Mish(),\n","      nn.BatchNorm2d(self.hidden_size)\n","    )\n","\n","    self.c2 = nn.Sequential( # 2\n","      self._conv2d(self.hidden_size, self.hidden_size),\n","      Mish(),\n","      nn.BatchNorm2d(self.hidden_size)\n","    )\n","\n","    self.c3 = nn.Sequential( # 3\n","      self._conv2d(self.hidden_size, self.hidden_size),\n","      Mish(),\n","      nn.BatchNorm2d(self.hidden_size)\n","    )\n","\n","    self.c4 = nn.Sequential( # 4\n","      self._conv2d(self.hidden_size, 1)\n","    )\n","\n","    return self.c1, self.c2, self.c3, self.c4 # return the values as a tuple\n","\n","  def __init__(self, hidden_size):\n","    super().__init__()\n","    self.hidden_size = hidden_size\n","    self._models = self._build_models()\n","\n","  def forward(self, img): # new feed forward loop manually moves from one layer to the next\n","    x = self._models[0](img)\n","    x1 = self._models[1](x)\n","    x2 = self._models[2](x1)\n","    x3 = self._models[3](x2)\n","    final_x = torch.mean(x3.view(x3.size(0), -1), dim=1)\n","\n","    return final_x\n","\n","# DENSE\n","class DenseMishCritic(nn.Module):\n","  def __init__(self, weights=densenet.DenseNet121_Weights.IMAGENET1K_V1):\n","    super(DenseMishCritic, self).__init__() # initialize using inheritance\n","    self._models = densenet.densenet121(weights=weights)\n","    self._models.train()\n","\n","  def forward(self, x):\n","    features = self._models.features(x)\n","    out = Mish()(features)\n","    out = F.avg_pool2d(out, kernel_size=7).view(features.size(0),-1)\n","    out = torch.mean(out.view(out.size(0),-1),dim=1)\n","    return out\n","\n","# RESIDUAL\n","class ResidualMishCritic(nn.Module):\n","  def __init__(self, num_classes=2):\n","    super(ResidualMishCritic, self).__init__() # initialize using inheritance\n","    self._models = resnet.ResNet(resnet.BasicBlock, [2,2,2,2], num_classes=num_classes)\n","    self.replace_relu_with_mish()\n","    self._models.train()\n","\n","  def forward(self, x):\n","    x = self._models.conv1(x)\n","    x = self._models.bn1(x)\n","    x = Mish()(x) # replace ReLU with Mish\n","    x = self._models.maxpool(x)\n","\n","    x = self._models.layer1(x)\n","    x = self._models.layer2(x)\n","    x = self._models.layer3(x)\n","    x = self._models.layer4(x)\n","\n","    x = self._models.avgpool(x)\n","    x = torch.mean(x.view(x.size(0), -1), dim=1)\n","    return x\n","\n","  # Helper method\n","  def replace_relu_with_mish(self):\n","    for name, module in self._models.named_children():\n","      if isinstance(module, nn.ReLU):\n","        setattr(self._models, name, Mish())\n","      elif isinstance(module, nn.Sequential):\n","        for child_name, child_module in module.named_children():\n","          if isinstance(child_module, nn.ReLU):\n","            setattr(module, child_name, Mish())"],"metadata":{"id":"B-KmaKMl5QU2","executionInfo":{"status":"ok","timestamp":1724372571491,"user_tz":360,"elapsed":5,"user":{"displayName":"a c","userId":"04528162853162008379"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["''' TEST '''\n","hidden_size = 64\n","dummy_input = torch.randn(1, 3, 224, 224)\n","\n","# Instantiate critics\n","basic_critic = BasicMishCritic(hidden_size)\n","dense_critic = DenseMishCritic()\n","residual_critic = ResidualMishCritic(num_classes=2)\n","\n","# Test BasicMishCritic\n","basic_output = basic_critic(dummy_input)\n","print(\"Basic Critic output shape:\", basic_output.shape)\n","assert basic_output.shape == torch.Size([1]), \"Basic Critic output shape is incorrect.\"\n","\n","# Test DenseMishCritic\n","dense_output = dense_critic(dummy_input)\n","print(\"Dense Critic output shape:\", dense_output.shape)\n","assert dense_output.shape == torch.Size([1]), \"Dense Critic output shape is incorrect.\"\n","\n","# Test ResidualMishCritic\n","residual_output = residual_critic(dummy_input)\n","print(\"Residual Critic output shape:\", residual_output.shape)\n","assert residual_output.shape == torch.Size([1]), \"Residual Critic output shape is incorrect.\"\n","\n","# Verify that ReLU has been replaced with Mish in ResidualMishCritic\n","for name, module in residual_critic._models.named_children():\n","    if isinstance(module, Mish):\n","        print(f\"Mish correctly placed in layer: {name}\")\n","    elif isinstance(module, nn.Sequential):\n","        for child_name, child_module in module.named_children():\n","            if isinstance(child_module, Mish):\n","                print(f\"Mish correctly placed in layer: {name}.{child_name}\")\n","\n","print(\"All tests passed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"50yblealiP-w","executionInfo":{"status":"ok","timestamp":1724372572987,"user_tz":360,"elapsed":1500,"user":{"displayName":"a c","userId":"04528162853162008379"}},"outputId":"036ea796-2bd8-4d21-cac8-b390b5046772"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Basic Critic output shape: torch.Size([1])\n","Dense Critic output shape: torch.Size([1])\n","Residual Critic output shape: torch.Size([1])\n","Mish correctly placed in layer: relu\n","All tests passed.\n"]}]}]}