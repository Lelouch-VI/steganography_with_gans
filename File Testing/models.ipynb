{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOEo8p5dvud1UNsFyJYA5sF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install reedsolo\n","from reedsolo import RSCodec"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lUQW5H3NM_77","executionInfo":{"status":"ok","timestamp":1724455295337,"user_tz":360,"elapsed":3439,"user":{"displayName":"a c","userId":"04528162853162008379"}},"outputId":"b5ce5095-7343-4ef6-c89d-5964108ac4de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: reedsolo in /usr/local/lib/python3.10/dist-packages (1.7.0)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YoaH2hoaww8q"},"outputs":[],"source":["''' LIBRARIES '''\n","import json\n","import datetime\n","import matplotlib.pyplot as plt\n","from torch.nn.functional import binary_cross_entropy_with_logits, mse_loss\n","from torchvision import datasets, transforms\n","from IPython.display import clear_output\n","import torchvision\n","from torch.optim import Adam # Adam optimizer\n","# import pytorch_ssim (this is what the origna)\n","from tqdm import tqdm\n","import torch\n","import os\n","import gc\n","from PIL import ImageFile\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","\n","\n","# Constants\n","DEFAULT_PATH = os.path.join(\n","    os.getcwd(),\n","    'train'\n",")\n","# os.makedirs(DEFAULT_PATH, exist_ok=True)\n","\n","# Metrics\n","METRIC_FIELDS = [\n","  'val.encoder_mse',\n","  'val.decoder_loss',\n","  'val.decoder_acc',\n","  'val.cover_score',\n","  'val.generated_score',\n","  'val.ssim',\n","  'val.psnr',\n","  'val.bpp',\n","  'train.encoder_mse',\n","  'train.decoder_loss',\n","  'train.decoder_acc',\n","  'train.cover_score',\n","  'train.generated_score',\n","]"]},{"cell_type":"code","source":["import os\n","print(os.listdir('/content/drive/My Drive/DU/COMP 3432 Machine Learning/Steganography with GANs'))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JGnG4ZenKV5S","executionInfo":{"status":"ok","timestamp":1724449572030,"user_tz":360,"elapsed":7,"user":{"displayName":"a c","userId":"04528162853162008379"}},"outputId":"aa2bdf90-c5b7-4c05-d075-ddd2be17cd15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['python notebook files', 'utils.py', 'decoder.py', 'encoder.py', 'critic.py', 'loader.py', 'models.py', '__pycache__', 'critics.py']\n"]}]},{"cell_type":"code","source":["# My own work; imported from drive\n","from google.colab import files\n","uploaded = files.upload()\n","\n","import sys\n","sys.path.append(\"\\\\wsl.localhost\\Arch\\home\\ac\\DU\\comp3432\\Project\")\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","# sys.path.append('/content/drive/My Drive/DU/COMP 3432 Machine Learning/Steganography with GANs')\n","\n","from loader  import MyDataset\n","from encoder import BasicMishEncoder, DenseMishEncoder, ResidualMishEncoder\n","from decoder import BasicMishDecoder, DenseMishDecoder\n","from critics import BasicMishCritic, DenseMishCritic, ResidualMishCritic\n","\n","# SteganoGAN utils file\n","from utils import bits_to_bytearray, bytearray_to_text, ssim, text_to_bits"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"id":"e-dOrb7XE7x4","executionInfo":{"status":"ok","timestamp":1724453485566,"user_tz":360,"elapsed":24436,"user":{"displayName":"a c","userId":"04528162853162008379"}},"outputId":"c7f3b0a8-15f9-4dde-9142-32a77ab6391e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-87a6ff11-929b-418f-ac01-76d4a81a1aaf\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-87a6ff11-929b-418f-ac01-76d4a81a1aaf\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving critics.py to critics.py\n","Saving decoder.py to decoder.py\n","Saving encoder.py to encoder.py\n","Saving loader.py to loader.py\n","Saving utils.py to utils.py\n"]}]},{"cell_type":"code","source":["class MISHSteganoGAN():\n","  # Initialization and Setup\n","  def __init__(self, data_depth, encoder, decoder, critic,\n","                cuda=False, log_dir=None, verbose=False):\n","    \"\"\" Parameters:\n","    - data_depth: int, depth of the data being embedded.\n","    - encoder: Encoder instance or class.\n","    - decoder: Decoder instance or class.\n","    - critic: Critic instance or class.\n","    - cuda: bool, whether to use GPU (default=False).\n","    - log_dir: str, path to log directory (default=None).\n","    - verbose: bool, verbosity flag (default=False).\n","    \"\"\"\n","    self.data_depth = data_depth\n","    self.encoder = encoder\n","    self.decoder = decoder\n","    self.critic = critic\n","    self.verbose = verbose\n","    self.log_dir = log_dir\n","    self.cuda = cuda\n","\n","    # Call the method to set the device (GPU or CPU)\n","    self._set_device()\n","\n","    # Move models to the appropriate device\n","    self.encoder.to(self.device)\n","    self.decoder.to(self.device)\n","    self.critic.to(self.device)\n","\n","    # Initialize optimizers and other training components later\n","    self.critic_optimizer = None\n","    self.encoder_decoder_optimizer = None\n","\n","    if self.log_dir:\n","      os.makedirs(self.log_dir, exist_ok=True)\n","\n","    if self.verbose:\n","      print(f\"Model initialized with data depth {self.data_depth}\")\n","\n","  def _set_device(self):\n","    \"\"\"\n","    Set the device to GPU if available and requested, otherwise use CPU.\n","\n","    I am using CUDA anyway but this was the most secure way to get this done\n","    \"\"\"\n","    if self.cuda and torch.cuda.is_available():\n","        self.device = torch.device('cuda')\n","        if self.verbose:\n","            print(\"Using CUDA device.\")\n","    else:\n","        self.device = torch.device('cpu')\n","        if self.cuda and not torch.cuda.is_available() and self.verbose:\n","            print(\"CUDA is not available. Defaulting to CPU.\")\n","        elif self.verbose:\n","            print(\"Using CPU device.\")\n","\n","\n","  # Payload Preparation\n","  def _random_data(self, cover):\n","    \"\"\"\n","    Parameters:\n","    - cover: torch.Tensor, the cover image tensor.\n","\n","    Returns:\n","    - torch.Tensor, random binary data tensor to embed in the cover.\n","    \"\"\"\n","    N, _, H, W = cover.size()\n","    return torch.zeros((N, self.data_depth, H, W), device=self.device).random_(0, 2)\n","\n","  def _make_payload(self, width, height, depth, text):\n","    \"\"\"\n","    Parameters:\n","    - width: int, width of the image.\n","    - height: int, height of the image.\n","    - depth: int, depth of the data.\n","    - text: str, the text data to be encoded.\n","\n","    Returns:\n","    - torch.Tensor, payload tensor formatted for encoding.\n","    \"\"\"\n","    message = text_to_bits(text) + [0] * 32  # Convert text to bits and pad with zeros.\n","    payload = message\n","    while len(payload) < width * height * depth:\n","        payload += message\n","    payload = payload[:width * height * depth]  # Truncate payload to fit within the image dimensions.\n","    return torch.FloatTensor(payload).view(1, depth, height, width).to(self.device)\n","\n","\n","  # Encoding and Decoding\n","  def _encode(self, cover, payload):\n","    \"\"\"\n","    Parameters:\n","    - cover: torch.Tensor, the cover image tensor.\n","    - payload: torch.Tensor, the data tensor to be encoded.\n","\n","    Returns:\n","    - torch.Tensor, the steganographic image with embedded data.\n","    \"\"\"\n","    generated = self.encoder(cover, payload)\n","    return generated\n","\n","  def _decode(self, stego):\n","    \"\"\"\n","    Parameters:\n","    - stego: torch.Tensor, the steganographic image tensor.\n","\n","    Returns:\n","    - torch.Tensor, the decoded data tensor.\n","    \"\"\"\n","    decoded = self.decoder(stego)\n","    return decoded\n","\n","  def _encode_decode(self, cover, quantize=False):\n","    \"\"\"\n","    Parameters:\n","    - cover: torch.Tensor, the cover image tensor.\n","    - quantize: bool, whether to quantize the stego image (default=False).\n","\n","    Returns:\n","    - tuple(torch.Tensor, torch.Tensor, torch.Tensor):\n","      - The generated stego image.\n","      - The original payload tensor.\n","      - The decoded data tensor.\n","    \"\"\"\n","    # Generate random data to embed\n","    payload = self._random_data(cover)\n","\n","    # Encode the data into the cover image using the specified encoder\n","    generated = self._encode(cover, payload)\n","\n","    # Quantization step (optional)\n","    if quantize:\n","        generated = (255.0 * (generated + 1.0) / 2.0).long()\n","        generated = 2.0 * generated.float() / 255.0 - 1.0\n","\n","    # Decode the data from the steganographic image using the specified decoder\n","    decoded = self._decode(generated)\n","\n","    return generated, payload, decoded\n","\n","  # Training\n","  def fit(self, train_loader, validate_loader, epochs=5):\n","    \"\"\"\n","    Parameters:\n","    - train_loader: DataLoader, the DataLoader for the training dataset.\n","    - validate_loader: DataLoader, the DataLoader for the validation dataset.\n","    - epochs: int, number of epochs to train (default=5).\n","    \"\"\"\n","    if self.critic_optimizer is None or self.decoder_optimizer is None:\n","      self.critic_optimizer, self.decoder_optimizer = self._get_optimizers()\n","\n","    for epoch in range(1, epochs + 1):\n","      print(f\"Epoch {epoch}/{epochs}\")\n","\n","      # Initialize metrics\n","      metrics = {field: [] for field in [ 'train.cover_score', 'train.generated_score',\n","                                          'train.encoder_mse', 'train.decoder_loss',\n","                                          'train.decoder_acc',\n","                                          'val.cover_score', 'val.generated_score',\n","                                          'val.encoder_mse', 'val.decoder_loss',\n","                                          'val.decoder_acc', 'val.ssim',\n","                                          'val.psnr', 'val.bpp']}\n","\n","      # Train the critic and encoder/decoder\n","      self._fit_critic(train_loader, metrics)\n","      self._fit_coders(train_loader, metrics)\n","\n","      # Validate the model\n","      self._validate(validate_loader, metrics)\n","\n","      # Logging and storing metrics could be added here\n","\n","      print(f\"Metrics after epoch {epoch}:\")\n","      for key, value in metrics.items():\n","        print(f\"{key}: {sum(value)/len(value):.4f}\")\n","\n","  def _fit_critic(self, train_loader, metrics):\n","    \"\"\"\n","    MISSING PARAMETERS:\n","    - Any additional control flags or hyperparameters.\n","\n","    Parameters:\n","    - train_loader: DataLoader, the DataLoader for the training dataset.\n","    - metrics: dict, dictionary to store training metrics.\n","    \"\"\"\n","    for cover, _ in tqdm(train_loader, desc=\"Training Critic\", leave=False):\n","      gc.collect()\n","      cover = cover.to(self.device)\n","      payload = self._random_data(cover)\n","      generated = self._encode(cover, payload)\n","\n","      cover_score = torch.mean(self.critic(cover))\n","      generated_score = torch.mean(self.critic(generated))\n","\n","      self.critic_optimizer.zero_grad()\n","      (cover_score - generated_score).backward()\n","      self.critic_optimizer.step()\n","\n","      # Clip critic weights to enforce Lipschitz continuity\n","      for p in self.critic.parameters():\n","        p.data.clamp_(-0.1, 0.1)\n","\n","      metrics['train.cover_score'].append(cover_score.item())\n","      metrics['train.generated_score'].append(generated_score.item())\n","\n","  def _fit_coders(self, train_loader, metrics):\n","    \"\"\"\n","    MISSING PARAMETERS:\n","    - Control flags or hyperparameters.\n","\n","    Parameters:\n","    - train_loader: DataLoader, the DataLoader for the training dataset.\n","    - metrics: dict, dictionary to store training metrics.\n","    \"\"\"\n","    for cover, _ in tqdm(train_loader, desc=\"Training Encoder/Decoder\", leave=False):\n","      gc.collect()\n","      cover = cover.to(self.device)\n","      generated, payload, decoded = self._encode_decode(cover)\n","\n","      encoder_mse = torch.nn.functional.mse_loss(generated, cover)\n","      decoder_loss = torch.nn.functional.binary_cross_entropy_with_logits(decoded, payload)\n","      decoder_acc = (decoded >= 0.0).eq(payload >= 0.5).sum().float() / payload.numel()\n","      generated_score = torch.mean(self.critic(generated))\n","\n","      self.decoder_optimizer.zero_grad()\n","      (100.0 * encoder_mse + decoder_loss + generated_score).backward()\n","      self.decoder_optimizer.step()\n","\n","      metrics['train.encoder_mse'].append(encoder_mse.item())\n","      metrics['train.decoder_loss'].append(decoder_loss.item())\n","      metrics['train.decoder_acc'].append(decoder_acc.item())\n","\n","  def _validate(self, validate_loader, metrics):\n","    \"\"\"\n","    MISSING PARAMETERS:\n","    - Validation metrics to track.\n","\n","    Parameters:\n","    - validate_loader: DataLoader, the DataLoader for the validation dataset.\n","    - metrics: dict, dictionary to store validation metrics.\n","    \"\"\"\n","    for cover, _ in tqdm(validate_loader, desc=\"Validating\", leave=False):\n","      gc.collect()\n","      cover = cover.to(self.device)\n","      generated, payload, decoded = self._encode_decode(cover, quantize=True)\n","\n","      encoder_mse = torch.nn.functional.mse_loss(generated, cover)\n","      decoder_loss = torch.nn.functional.binary_cross_entropy_with_logits(decoded, payload)\n","      decoder_acc = (decoded >= 0.0).eq(payload >= 0.5).sum().float() / payload.numel()\n","      generated_score = torch.mean(self.critic(generated))\n","      cover_score = torch.mean(self.critic(cover))\n","      ssim_score = ssim(cover, generated)\n","      psnr_score = 10 * torch.log10(4 / encoder_mse).item()\n","      bpp_score = self.data_depth * (2 * decoder_acc.item() - 1)\n","\n","      metrics['val.encoder_mse'].append(encoder_mse.item())\n","      metrics['val.decoder_loss'].append(decoder_loss.item())\n","      metrics['val.decoder_acc'].append(decoder_acc.item())\n","      metrics['val.cover_score'].append(cover_score.item())\n","      metrics['val.generated_score'].append(generated_score.item())\n","      metrics['val.ssim'].append(ssim_score.item())\n","      metrics['val.psnr'].append(psnr_score.item())\n","      metrics['val.bpp'].append(bpp_score)\n","\n","  # Optimization and Loss Functions\n","  def _get_optimizers(self):\n","    \"\"\"\n","    Create optimizers for the critic and encoder/decoder.\n","    Set the learning rate at a constant of 1e-4, the same as the original\n","\n","    Returns (tuple):\n","    - critic_optimizer: Optimizer, the optimizer for the critic.\n","    - decoder_optimizer: Optimizer, the optimizer for the decoder and encoder combined.\n","    \"\"\"\n","    # Optimizer for the critic\n","    critic_optimizer = Adam(self.critic.parameters(), lr=1e-4)\n","\n","    # Optimizer for both the encoder and decoder\n","    decoder_optimizer = Adam(list(self.encoder.parameters()) + list(self.decoder.parameters()), lr=1e-4)\n","\n","    return critic_optimizer, decoder_optimizer\n","  # Saving and Loading\n","  def save(self, path):\n","    \"\"\"\n","    Parameters:\n","    - path: str, the file path to save the model.\n","    \"\"\"\n","    model_state = {\n","      'encoder': self.encoder.state_dict(),\n","      'decoder': self.decoder.state_dict(),\n","      'critic': self.critic.state_dict(),\n","      'critic_optimizer': self.critic_optimizer.state_dict(),\n","      'decoder_optimizer': self.decoder_optimizer.state_dict(),\n","      'epochs': self.epochs\n","    }\n","    torch.save(model_state, path)\n","    if self.verbose:\n","      print(f\"Model saved to {path}\")\n","\n","\n","  def load(self, path, cuda=True, verbose=False):\n","    \"\"\"\n","    Parameters:\n","    - path: str, the file path to load the model from.\n","    - cuda: bool, whether to use GPU (default=True).\n","    \"\"\"\n","    model_state = torch.load(path, map_location='cuda' if cuda and torch.cuda.is_available() else 'cpu')\n","\n","    # Initialize the model\n","    model = self.__class__(data_depth=model_state['encoder']['weight'].size(1),\n","                encoder=self.encoder,\n","                decoder=self.decoder,\n","                critic=self.critic,\n","                cuda=cuda,\n","                verbose=verbose)\n","\n","    # Load model states\n","    model.encoder.load_state_dict(model_state['encoder'])\n","    model.decoder.load_state_dict(model_state['decoder'])\n","    model.critic.load_state_dict(model_state['critic'])\n","    model.critic_optimizer.load_state_dict(model_state['critic_optimizer'])\n","    model.decoder_optimizer.load_state_dict(model_state['decoder_optimizer'])\n","    model.epochs = model_state['epochs']\n","\n","    if model.verbose:\n","      print(f\"Model loaded from {path}\")\n","\n","    return model\n","\n","\n","  # Logging and Visualization Methods\n","  def _log_metrics(self, metrics, epoch):\n","    \"\"\"\n","    MISSING PARAMETERS:\n","    - Logging directory or file path.\n","\n","    Parameters:\n","    - metrics: dict, dictionary of metrics to log.\n","    - epoch: int, current training epoch.\n","    \"\"\"\n","    metrics['epoch'] = epoch\n","\n","    if self.log_dir:\n","      if not os.path.exists(self.log_dir):\n","        os.makedirs(self.log_dir)\n","      metrics_path = os.path.join(self.log_dir, 'metrics.json')\n","\n","      # Append the new metrics to the log file\n","      with open(metrics_path, 'a') as f:\n","        json.dump(metrics, f)\n","        f.write('\\n')\n","\n","    if self.verbose:\n","      print(f\"Metrics logged to {metrics_path}\")\n","\n","  def _plot_metrics(self, metrics, epoch):\n","    \"\"\"\n","    Plot the training and validation metrics for the current epoch.\n","\n","    Parameters:\n","    - metrics (dict): Dictionary of metrics to plot.\n","    - epoch (int): The current epoch number.\n","    \"\"\"\n","    # Define the metrics to plot\n","    metric_names = ['encoder_mse', 'decoder_loss', 'decoder_acc', 'cover_score', 'generated_score', 'ssim', 'psnr', 'bpp']\n","\n","    # Create a figure for plotting\n","    plt.figure(figsize=(12, 8))\n","\n","    for i, metric in enumerate(metric_names):\n","      # Plot the metric\n","      plt.subplot(2, 4, i+1)\n","      plt.plot(metrics['train.' + metric], label=f'Train {metric}')\n","      plt.plot(metrics['val.' + metric], label=f'Val {metric}')\n","      plt.xlabel('Epoch')\n","      plt.ylabel(metric)\n","      plt.title(f'{metric} over epochs')\n","      plt.legend()\n","      plt.grid(True)\n","\n","    # Adjust layout and show the plot\n","    plt.tight_layout()\n","    plt.show()\n","\n","    # Save the plot if log_dir is provided\n","    if self.log_dir:\n","      plot_path = os.path.join(self.log_dir, f'metrics_epoch_{epoch}.png')\n","      plt.savefig(plot_path)\n","      if self.verbose:\n","        print(f\"Plot saved to {plot_path}\")\n"],"metadata":{"id":"jb2HMIzXNQY5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()\n","\n","cover_dir = \"C:\\Users\\aeden\\Desktop\\TEST\\cover\"\n","\n","\n","SteganoGAN = MISHSteganoGAN()\n","\n","\n","# List all image files in the cover directory\n","cover_imgs = sorted([os.path.join(cover_dir, f) for f in os.listdir(cover_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n","\n","\n","\n","# Create the data loader with shuffle=True\n","data_loader = MyDataset.create_data_loader(cover_imgs, stego_imgs, transform=None, batch_size=4, shuffle=True, num_workers=0)"],"metadata":{"id":"xQWFFQLXPcnV"},"execution_count":null,"outputs":[]}]}